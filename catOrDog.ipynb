{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c696d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import imghdr\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea1736",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"Downloads/catDog\" # catDog file contains two files for cat and dog images respectively\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55773389",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"Downloads/catDog\"\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']\n",
    "\n",
    "# deleteCnt = 0\n",
    "for imageClass in os.listdir(dataDir):\n",
    "    test = str(imageClass)\n",
    "    if test == '.DS_Store': # some invisible file I can't delete manually\n",
    "        continue\n",
    "        \n",
    "    for image in os.listdir(os.path.join(dataDir, imageClass)):\n",
    "        imagePath = os.path.join(dataDir, imageClass, image)\n",
    "        \n",
    "        try:\n",
    "          # removes images that are not compatible\n",
    "          img = cv2.imread(imagePath)\n",
    "          tip = imghdr.what(imagePath)\n",
    "          if tip not in image_exts:\n",
    "              print(\"Image not in list of extensions\".format(imagePath))\n",
    "              # os.remove(imagePath) this function does not trash images, it deletes\n",
    "              # deleteCnt += 1\n",
    "           \n",
    "          # error will be caught if image is corrupted\n",
    "          img_bytes = tf.io.read_file(path)\n",
    "          decoded_img = tf.io.decode_image(img_bytes)\n",
    "        \n",
    "        except Exception as e:\n",
    "          #os.remove(imagePath)\n",
    "          deleteCnt += 1\n",
    "            \n",
    "# print(deleteCnt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965465b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "for imageClass in os.listdir(dataDir): # removes imgs that aren't compatible\n",
    "  for image_path in os.listdir(os.path.join(dataDir, imageClass)):\n",
    "    path = os.path.join(dataDir, imageClass, image_path)\n",
    "    try:\n",
    "      img_bytes = tf.io.read_file(path)\n",
    "      decoded_img = tf.io.decode_image(img_bytes)\n",
    "    except tf.errors.InvalidArgumentError as e:\n",
    "      print(\"Found!\")\n",
    "      os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71750668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5337660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# stores images in batches, each batch has 32 images, images are stored as a 2D array of integers\n",
    "ds = tf.keras.utils.image_dataset_from_directory(dataDir) # shape of each batch: [image][label ([0,1])]\n",
    "#length of ds = number of images/32 \n",
    "\n",
    "ds = ds.map(lambda x,y: (x/255, y)) # divides all pixel values ([0, 255] inclusive) by 255\n",
    "\n",
    "# training data will be 80%, validation data will be 20%, in number of batches\n",
    "trainSize = int(len(ds) * .8)+1\n",
    "valSize = int(len(ds) * .2)\n",
    "\n",
    "# we can use an iterator to traverse through batches\n",
    "trainDS = ds.take(trainSize)\n",
    "valDS = ds.skip(trainSize).take(valSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c26120",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.keras.utils.image_dataset_from_directory(dataDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f52892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize = int(len(ds) * .8)+1\n",
    "valSize = int(len(ds) * .2)\n",
    "\n",
    "# 80% training, 20% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDS = ds.take(trainSize)\n",
    "valDS = ds.skip(trainSize).take(valSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4f6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, RandomFlip, RandomRotation, RandomZoom, BatchNormalization\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cff69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "    input_shape=(256,256,3)),\n",
    "    layers.RandomRotation(0.5),\n",
    "    layers.RandomZoom(0.5),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bdd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reset training\n",
    "del model\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf09df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 22:49:17.253274: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b7400e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 252, 252, 32)      9248      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 252, 252, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 126, 126, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 126, 126, 32)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 122, 122, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 122, 122, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 61, 61, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 61, 61, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 59, 59, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 57, 57, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 57, 57, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 64)        73792     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4719104   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,118,497\n",
      "Trainable params: 5,117,921\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# augmentation will not be called for predictions\n",
    "data_augmentation\n",
    "model.add(layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(256, 256, 3)))\n",
    "model.add(layers.Conv2D(32, (3,3), activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3,3), activation=\"relu\"))\n",
    "model.add(layers.Conv2D(128, (3,3), activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRateReduction = ReduceLROnPlateau(monitor = 'val_accuracy', \n",
    "                                          patience = 1, \n",
    "                                          verbose = 1, \n",
    "                                          factor = .5, \n",
    "                                          min_lr = .00001)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "callbacks = [learningRateReduction]\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4670ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(trainDS, epochs = 50, validation_data = valDS, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='red', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='blue', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2146fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='red', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='blue', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "261f6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "testImg = cv2.imread(\"Downloads/dogs/dog3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d6ec02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(testImg, (256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "998e80ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ef74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ans <= .5:\n",
    "    print(\"Its a cat!\")\n",
    "else:\n",
    "    print(\"Not a cat!\")\n",
    "    \n",
    "print(ans)\n",
    "\n",
    "# cat1: 0.0625807\n",
    "# cat2: 0.00000000000014656887\n",
    "# cat3: 0.996319\n",
    "# dog1: 1\n",
    "# dog2: 0.23557787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a49a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/catOrDog.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2888bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model/catOrDog.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
